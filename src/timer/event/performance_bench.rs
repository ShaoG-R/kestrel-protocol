//! é›¶æ‹·è´äº‹ä»¶ç³»ç»Ÿæ€§èƒ½åŸºå‡†æµ‹è¯•
//! Zero-copy event system performance benchmarks

use super::zero_copy::*;
use super::traits::*;
use super::*;
use crate::core::endpoint::timing::TimeoutEvent;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};

/// æ€§èƒ½åŸºå‡†æµ‹è¯•é…ç½®
/// Performance benchmark configuration
#[derive(Debug, Clone)]
pub struct BenchConfig {
    pub batch_sizes: Vec<usize>,
    pub dispatcher_counts: Vec<usize>,
    pub slot_counts: Vec<usize>,
    pub iterations: usize,
}

impl Default for BenchConfig {
    fn default() -> Self {
        Self {
            batch_sizes: vec![32, 128, 512, 2048, 8192],
            dispatcher_counts: vec![1, 4, 8, 16],
            slot_counts: vec![64, 256, 1024, 4096],
            iterations: 100,
        }
    }
}

/// æ€§èƒ½æµ‹è¯•ç»“æœ
/// Performance test results
#[derive(Debug, Clone)]
pub struct BenchResult {
    pub config_name: String,
    pub total_events: usize,
    pub duration: Duration,
    pub events_per_second: f64,
    pub nanoseconds_per_event: f64,
    pub memory_usage_mb: f64,
}

impl BenchResult {
    pub fn new(config_name: String, total_events: usize, duration: Duration) -> Self {
        let events_per_second = total_events as f64 / duration.as_secs_f64();
        let nanoseconds_per_event = duration.as_nanos() as f64 / total_events as f64;
        
        Self {
            config_name,
            total_events,
            duration,
            events_per_second,
            nanoseconds_per_event,
            memory_usage_mb: 0.0, // éœ€è¦ä¸“é—¨çš„å†…å­˜ç›‘æ§
        }
    }
    
    pub fn print_summary(&self) {
        println!("=== {} ===", self.config_name);
        println!("  æ€»äº‹ä»¶æ•°: {}", self.total_events);
        println!("  æ€»è€—æ—¶: {:?}", self.duration);
        println!("  äº‹ä»¶/ç§’: {:.0}", self.events_per_second);
        println!("  çº³ç§’/äº‹ä»¶: {:.1}", self.nanoseconds_per_event);
        println!("  å†…å­˜ä½¿ç”¨: {:.2} MB", self.memory_usage_mb);
        println!();
    }
}

/// é›¶æ‹·è´æ€§èƒ½åŸºå‡†æµ‹è¯•å™¨
/// Zero-copy performance benchmarker
pub struct ZeroCopyBenchmarker {
    config: BenchConfig,
    results: Vec<BenchResult>,
}

impl ZeroCopyBenchmarker {
    pub fn new(config: BenchConfig) -> Self {
        Self {
            config,
            results: Vec::new(),
        }
    }
    
    /// åˆ›å»ºæµ‹è¯•äº‹ä»¶æ•°æ®
    /// Create test event data
    fn create_test_events(count: usize) -> Vec<TimerEventData<TimeoutEvent>> {
        (0..count)
            .map(|i| TimerEventData::new(i as u32, TimeoutEvent::IdleTimeout))
            .collect()
    }
    
    /// åŸºå‡†æµ‹è¯•ï¼šFastEventSlot å†™å…¥æ€§èƒ½
    /// Benchmark: FastEventSlot write performance
    pub fn bench_fast_event_slot_writes(&mut self) {
        for &slot_count in &self.config.slot_counts {
            for &batch_size in &self.config.batch_sizes {
                let config_name = format!("FastEventSlot_{}slots_{}batch", slot_count, batch_size);
                
                let slot = EventSlot::<TimeoutEvent>::new(slot_count);
                let events = Self::create_test_events(batch_size);
                
                let start = Instant::now();
                
                for _ in 0..self.config.iterations {
                    for event in events.clone() {
                        slot.write_event(event);
                    }
                }
                
                let duration = start.elapsed();
                let total_events = batch_size * self.config.iterations;
                
                let result = BenchResult::new(config_name, total_events, duration);
                result.print_summary();
                self.results.push(result);
            }
        }
    }
    
    /// åŸºå‡†æµ‹è¯•ï¼šZeroCopyBatchDispatcher åˆ†å‘æ€§èƒ½
    /// Benchmark: ZeroCopyBatchDispatcher dispatch performance  
    pub fn bench_batch_dispatcher(&mut self) {
        for &dispatcher_count in &self.config.dispatcher_counts {
            for &batch_size in &self.config.batch_sizes {
                let config_name = format!("BatchDispatcher_{}disp_{}batch", dispatcher_count, batch_size);
                
                let dispatcher = ZeroCopyBatchDispatcher::<TimeoutEvent>::new(256, dispatcher_count, 1000);
                
                let start = Instant::now();
                let mut total_dispatched = 0;
                
                for _ in 0..self.config.iterations {
                    let events = Self::create_test_events(batch_size);
                    total_dispatched += dispatcher.batch_dispatch_events(events);
                }
                
                let duration = start.elapsed();
                
                let result = BenchResult::new(config_name, total_dispatched, duration);
                result.print_summary();
                self.results.push(result);
            }
        }
    }
    
    /// åŸºå‡†æµ‹è¯•ï¼šRefEventHandler å¤„ç†æ€§èƒ½
    /// Benchmark: RefEventHandler processing performance
    pub fn bench_ref_event_handler(&mut self) {
        for &batch_size in &self.config.batch_sizes {
            let config_name = format!("RefEventHandler_{}batch", batch_size);
            
            let processed_count = Arc::new(AtomicUsize::new(0));
            let processed_count_clone = Arc::clone(&processed_count);
            
            let handler = RefEventHandler::new(move |_event: &TimerEventData<TimeoutEvent>| {
                processed_count_clone.fetch_add(1, Ordering::Relaxed);
                true
            });
            
            let events = Self::create_test_events(batch_size);
            let event_refs: Vec<&TimerEventData<TimeoutEvent>> = events.iter().collect();
            
            let start = Instant::now();
            
            for _ in 0..self.config.iterations {
                handler.batch_deliver_event_refs(&event_refs);
            }
            
            let duration = start.elapsed();
            let total_events = batch_size * self.config.iterations;
            
            let result = BenchResult::new(config_name, total_events, duration);
            result.print_summary();
            self.results.push(result);
        }
    }
    
    /// åŸºå‡†æµ‹è¯•ï¼šEventFactory åˆ›å»ºæ€§èƒ½
    /// Benchmark: EventFactory creation performance
    pub fn bench_event_factory(&mut self) {
        for &batch_size in &self.config.batch_sizes {
            let config_name = format!("EventFactory_{}batch", batch_size);
            
            let factory = EventFactory::<TimeoutEvent>::new();
            let requests: Vec<(ConnectionId, TimeoutEvent)> = (0..batch_size)
                .map(|i| (i as u32, TimeoutEvent::IdleTimeout))
                .collect();
            
            let start = Instant::now();
            
            for _ in 0..self.config.iterations {
                let _events = factory.batch_create_events(&requests);
            }
            
            let duration = start.elapsed();
            let total_events = batch_size * self.config.iterations;
            
            let result = BenchResult::new(config_name, total_events, duration);
            result.print_summary();
            self.results.push(result);
        }
    }
    
    /// åŸºå‡†æµ‹è¯•ï¼šå®Œæ•´é›¶æ‹·è´å·¥ä½œæµ
    /// Benchmark: Complete zero-copy workflow
    pub fn bench_complete_workflow(&mut self) {
        for &batch_size in &self.config.batch_sizes {
            let config_name = format!("CompleteWorkflow_{}batch", batch_size);
            
            let factory = EventFactory::<TimeoutEvent>::new();
            let dispatcher = ZeroCopyBatchDispatcher::<TimeoutEvent>::new(512, 8, 1000);
            
            let requests: Vec<(ConnectionId, TimeoutEvent)> = (0..batch_size)
                .map(|i| (i as u32, TimeoutEvent::IdleTimeout))
                .collect();
            
            let start = Instant::now();
            let mut total_dispatched = 0;
            
            for _ in 0..self.config.iterations {
                // 1. åˆ›å»ºäº‹ä»¶
                let events = factory.batch_create_events(&requests);
                
                // 2. åˆ†å‘äº‹ä»¶
                total_dispatched += dispatcher.batch_dispatch_events(events);
            }
            
            let duration = start.elapsed();
            
            let result = BenchResult::new(config_name, total_dispatched, duration);
            result.print_summary();
            self.results.push(result);
        }
    }
    
    /// åŸºå‡†æµ‹è¯•ï¼šæ™ºèƒ½åˆ†å‘å™¨ vs ä¼˜åŒ–åˆ†å‘å™¨ vs åŸå§‹å®ç°
    /// Benchmark: Smart dispatcher vs Optimized dispatcher vs Original implementation
    pub fn bench_smart_vs_optimized_vs_original(&mut self) {
        use super::lockfree_ring::OptimizedZeroCopyDispatcher;
        use super::zero_copy::SmartZeroCopyDispatcher;
        
        for &batch_size in &self.config.batch_sizes {
            let config_name_orig = format!("Original_{}batch", batch_size);
            let config_name_opt = format!("Optimized_{}batch", batch_size);
            let config_name_smart = format!("Smart_{}batch", batch_size);
            
            // æµ‹è¯•åŸå§‹å®ç°
            let original_dispatcher = ZeroCopyBatchDispatcher::<TimeoutEvent>::new(512, 8, 1000);
            let start = Instant::now();
            let mut total_dispatched_orig = 0;
            
            for _ in 0..self.config.iterations {
                let events = Self::create_test_events(batch_size);
                total_dispatched_orig += original_dispatcher.batch_dispatch_events(events);
            }
            let duration_orig = start.elapsed();
            
            // æµ‹è¯•ä¼˜åŒ–å®ç°
            let optimized_dispatcher = OptimizedZeroCopyDispatcher::<TimeoutEvent>::new(512, 8);
            let start = Instant::now();
            let mut total_dispatched_opt = 0;
            
            for _ in 0..self.config.iterations {
                let events = Self::create_test_events(batch_size);
                total_dispatched_opt += optimized_dispatcher.batch_dispatch_events(events);
            }
            let duration_opt = start.elapsed();
            
            // æµ‹è¯•æ™ºèƒ½å®ç°ï¼ˆé›†æˆå†…å­˜æ± ï¼‰
            let smart_dispatcher = SmartZeroCopyDispatcher::<TimeoutEvent>::new(512, 8, 1000);
            let start = Instant::now();
            let mut total_dispatched_smart = 0;
            
            for _ in 0..self.config.iterations {
                let events = Self::create_test_events(batch_size);
                total_dispatched_smart += smart_dispatcher.batch_dispatch_events(events);
            }
            let duration_smart = start.elapsed();
            
            // è®°å½•ç»“æœ
            let result_orig = BenchResult::new(config_name_orig, total_dispatched_orig, duration_orig);
            let result_opt = BenchResult::new(config_name_opt, total_dispatched_opt, duration_opt);
            let result_smart = BenchResult::new(config_name_smart, total_dispatched_smart, duration_smart);
            
            result_orig.print_summary();
            result_opt.print_summary();
            result_smart.print_summary();
            
            // æ‰“å°æ™ºèƒ½åˆ†å‘å™¨çš„è¯¦ç»†ç»Ÿè®¡
            let smart_stats = smart_dispatcher.get_detailed_stats();
            smart_stats.print_summary();
            
            // è®¡ç®—æ€§èƒ½æå‡
            let improvement_opt = if duration_orig.as_nanos() > 0 {
                (duration_orig.as_nanos() as f64 - duration_opt.as_nanos() as f64) / duration_orig.as_nanos() as f64 * 100.0
            } else {
                0.0
            };
            
            let improvement_smart = if duration_orig.as_nanos() > 0 {
                (duration_orig.as_nanos() as f64 - duration_smart.as_nanos() as f64) / duration_orig.as_nanos() as f64 * 100.0
            } else {
                0.0
            };
            
            println!("ğŸš€ ä¼˜åŒ–ç‰ˆæ€§èƒ½æå‡: {:.1}%", improvement_opt);
            println!("ğŸ§  æ™ºèƒ½ç‰ˆæ€§èƒ½æå‡: {:.1}%\n", improvement_smart);
            
            self.results.push(result_orig);
            self.results.push(result_opt);
            self.results.push(result_smart);
        }
    }

    /// åŸºå‡†æµ‹è¯•ï¼šæ™ºèƒ½åˆ†å‘å™¨çš„ç«¯åˆ°ç«¯å·¥ä½œæµï¼ˆåˆ›å»º+åˆ†å‘+å›æ”¶ï¼‰
    /// Benchmark: Smart dispatcher end-to-end workflow (create + dispatch + recycle)
    pub fn bench_smart_end_to_end_workflow(&mut self) {
        // å…ˆè¿è¡Œä¼˜åŒ–ç‰ˆæœ¬çš„åŸºå‡†æµ‹è¯•
        self.bench_smart_end_to_end_workflow_optimized();
        
        // ç„¶åè¿è¡ŒåŸå§‹ç‰ˆæœ¬è¿›è¡Œå¯¹æ¯”
        self.bench_smart_end_to_end_workflow_original();
    }
    
    /// ä¼˜åŒ–ç‰ˆæœ¬çš„SmartEndToEndå·¥ä½œæµï¼ˆå‡å°‘ä¸å¿…è¦çš„å†…å­˜æ“ä½œï¼‰
    /// Optimized version of SmartEndToEnd workflow (reduced unnecessary memory operations)
    pub fn bench_smart_end_to_end_workflow_optimized(&mut self) {
        use super::zero_copy::SmartZeroCopyDispatcher;
        
        for &batch_size in &self.config.batch_sizes {
            let config_name = format!("SmartEndToEndOptimized_{}batch", batch_size);
            
            let smart_dispatcher = SmartZeroCopyDispatcher::<TimeoutEvent>::new(512, 8, 1000);
            let requests: Vec<(u32, TimeoutEvent)> = (0..batch_size)
                .map(|i| (i as u32, TimeoutEvent::IdleTimeout))
                .collect();
            
            let start = Instant::now();
            let mut total_dispatched = 0;
            
            // ä¼˜åŒ–ï¼šä»…åœ¨å¿…è¦æ—¶è¿›è¡Œå†…å­˜ç®¡ç†ï¼Œå¤§å¤§å‡å°‘å¼€é”€
            // Optimization: only perform memory management when necessary, greatly reducing overhead
            for iteration in 0..self.config.iterations {
                // 1. æ™ºèƒ½åˆ›å»ºå’Œåˆ†å‘ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
                total_dispatched += smart_dispatcher.create_and_dispatch_events(&requests);
                
                // 2. å†…å­˜ç®¡ç†ï¼šåªåœ¨æ¯10æ¬¡è¿­ä»£åæ‰§è¡Œä¸€æ¬¡ï¼Œè€Œä¸æ˜¯æ¯æ¬¡éƒ½æ‰§è¡Œ
                // Memory management: execute only after every 10 iterations, not every time
                if iteration % 10 == 9 {
                    // æ‰¹é‡æ¶ˆè´¹å°‘é‡äº‹ä»¶ç”¨äºæµ‹è¯•å®Œæ•´æ€§
                    // Batch consume small amount of events for testing completeness
                    let consumed_events = smart_dispatcher.batch_consume_events(5);
                    if !consumed_events.is_empty() {
                        smart_dispatcher.batch_return_to_pool(consumed_events);
                    }
                }
            }
            
            let duration = start.elapsed();
            
            let result = BenchResult::new(config_name, total_dispatched, duration);
            result.print_summary();
            
            // åœ¨æœ€åè·å–ä¸€æ¬¡è¯¦ç»†ç»Ÿè®¡
            // Get detailed statistics at the end
            let stats = smart_dispatcher.get_detailed_stats();
            println!("  ğŸš€ ä¼˜åŒ–ç‰ˆæ€§èƒ½ç»Ÿè®¡:");
            println!("    - æˆåŠŸåˆ†å‘: {}", stats.total_dispatched);
            println!("    - æˆåŠŸç‡: {:.1}%", stats.success_rate * 100.0);
            println!("    - å¹³å‡åˆ©ç”¨ç‡: {:.1}%", stats.average_slot_utilization * 100.0);
            println!();
            
            self.results.push(result);
        }
    }
    
    /// åŸå§‹ç‰ˆæœ¬çš„SmartEndToEndå·¥ä½œæµï¼ˆç”¨äºæ€§èƒ½å¯¹æ¯”ï¼‰
    /// Original version of SmartEndToEnd workflow (for performance comparison)
    pub fn bench_smart_end_to_end_workflow_original(&mut self) {
        use super::zero_copy::SmartZeroCopyDispatcher;
        
        for &batch_size in &self.config.batch_sizes {
            let config_name = format!("SmartEndToEndOriginal_{}batch", batch_size);
            
            let smart_dispatcher = SmartZeroCopyDispatcher::<TimeoutEvent>::new(512, 8, 1000);
            let requests: Vec<(u32, TimeoutEvent)> = (0..batch_size)
                .map(|i| (i as u32, TimeoutEvent::IdleTimeout))
                .collect();
            
            let start = Instant::now();
            let mut total_dispatched = 0;
            
            for _ in 0..self.config.iterations {
                // 1. æ™ºèƒ½åˆ›å»ºå’Œåˆ†å‘
                total_dispatched += smart_dispatcher.create_and_dispatch_events(&requests);
                
                // ä¼˜åŒ–ï¼šå‡å°‘æ¶ˆè´¹å’Œå›æ”¶çš„é¢‘ç‡ï¼Œåªåœ¨å¿…è¦æ—¶æ‰§è¡Œ
                // Optimization: reduce consumption and recycling frequency, execute only when necessary
                // æ¯4è½®è¿­ä»£æ‰æ‰§è¡Œä¸€æ¬¡æ¶ˆè´¹å’Œå›æ”¶ï¼Œå‡å°‘å¼€é”€
                // Execute consumption and recycling only every 4 iterations to reduce overhead
                if total_dispatched % (batch_size * 4) == 0 {
                    // 2. æ‰¹é‡æ¶ˆè´¹ - ä½¿ç”¨æ›´å°çš„æ¶ˆè´¹é‡å‡å°‘é”ç«äº‰
                    // Batch consume - use smaller consumption amount to reduce lock contention
                    let consume_size = std::cmp::min(batch_size / 4, 16);
                    let consumed_events = smart_dispatcher.batch_consume_events(consume_size);
                    
                    // 3. æ‰¹é‡å›æ”¶åˆ°å†…å­˜æ±  - ä»…åœ¨æœ‰æ¶ˆè´¹äº‹ä»¶æ—¶æ‰§è¡Œ
                    // Batch return to memory pool - execute only when there are consumed events
                    if !consumed_events.is_empty() {
                        smart_dispatcher.batch_return_to_pool(consumed_events);
                    }
                }
            }
            
            let duration = start.elapsed();
            
            let result = BenchResult::new(config_name, total_dispatched, duration);
            result.print_summary();
            
            // æ‰“å°è¯¦ç»†æ€§èƒ½ç»Ÿè®¡
            let stats = smart_dispatcher.get_detailed_stats();
            println!("  ğŸ“Š åŸå§‹ç‰ˆæ€§èƒ½ç»Ÿè®¡:");
            println!("    - æˆåŠŸåˆ†å‘: {}", stats.total_dispatched);
            println!("    - æˆåŠŸç‡: {:.1}%", stats.success_rate * 100.0);
            println!("    - å¹³å‡åˆ©ç”¨ç‡: {:.1}%", stats.average_slot_utilization * 100.0);
            println!();
            
            self.results.push(result);
        }
    }
    
    /// åŸºå‡†æµ‹è¯•ï¼šå†…å­˜æ± ä¼˜åŒ–æ•ˆæœ
    /// Benchmark: Memory pool optimization effects
    pub fn bench_memory_pool_optimization(&mut self) {
        use super::memory_pool::OptimizedBatchProcessor;
        
        for &batch_size in &self.config.batch_sizes {
            let config_name = format!("MemoryPool_{}batch", batch_size);
            
            let processor = OptimizedBatchProcessor::<TimeoutEvent>::new(1000, 32);
            let requests: Vec<(u32, TimeoutEvent)> = (0..batch_size)
                .map(|i| (i as u32, TimeoutEvent::IdleTimeout))
                .collect();
            
            let start = Instant::now();
            
            for _ in 0..self.config.iterations {
                let events = processor.create_events_optimized(&requests);
                processor.process_completed(events);
            }
            
            let duration = start.elapsed();
            let total_events = batch_size * self.config.iterations;
            
            let result = BenchResult::new(config_name, total_events, duration);
            result.print_summary();
            
            // æ‰“å°å†…å­˜æ± ç»Ÿè®¡
            let (processed, created, reused, reuse_rate, large_batch_ratio) = processor.get_performance_stats();
            println!("  ğŸ“Š å†…å­˜æ± ç»Ÿè®¡:");
            println!("    - å¤„ç†äº‹ä»¶: {}", processed);
            println!("    - æ–°å»ºå¯¹è±¡: {}", created);
            println!("    - å¤ç”¨å¯¹è±¡: {}", reused);
            println!("    - å¤ç”¨ç‡: {:.1}%", reuse_rate * 100.0);
            println!("    - å¤§æ‰¹é‡å¤„ç†ç‡: {:.1}%", large_batch_ratio * 100.0);
            println!();
            
            self.results.push(result);
        }
    }

    /// è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•
    /// Run all benchmarks
    pub fn run_all_benchmarks(&mut self) {
        println!("=== é›¶æ‹·è´äº‹ä»¶ç³»ç»Ÿæ€§èƒ½åŸºå‡†æµ‹è¯• ===");
        println!("é…ç½®: {:?}\n", self.config);
        
        println!("1. FastEventSlot å†™å…¥æ€§èƒ½...");
        self.bench_fast_event_slot_writes();
        
        println!("2. BatchDispatcher åˆ†å‘æ€§èƒ½...");
        self.bench_batch_dispatcher();
        
        println!("3. RefEventHandler å¤„ç†æ€§èƒ½...");
        self.bench_ref_event_handler();
        
        println!("4. EventFactory åˆ›å»ºæ€§èƒ½...");
        self.bench_event_factory();
        
        println!("5. å®Œæ•´å·¥ä½œæµæ€§èƒ½...");
        self.bench_complete_workflow();
        
        println!("6. æ™ºèƒ½ç‰ˆ vs ä¼˜åŒ–ç‰ˆ vs åŸå§‹ç‰ˆå¯¹æ¯”...");
        self.bench_smart_vs_optimized_vs_original();
        
        println!("7. æ™ºèƒ½åˆ†å‘å™¨ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•ï¼ˆä¼˜åŒ–ç‰ˆ vs åŸå§‹ç‰ˆï¼‰...");
        self.bench_smart_end_to_end_workflow();
        
        println!("8. å†…å­˜æ± ä¼˜åŒ–æ•ˆæœ...");
        self.bench_memory_pool_optimization();
        
        self.print_performance_analysis();
    }
    
    /// æ‰“å°æ€§èƒ½åˆ†ææŠ¥å‘Š
    /// Print performance analysis report
    pub fn print_performance_analysis(&self) {
        println!("=== æ€§èƒ½åˆ†ææŠ¥å‘Š ===");
        
        // æŒ‰ç»„ä»¶åˆ†ç±»æ€§èƒ½ç»“æœ
        let mut component_results: std::collections::HashMap<String, Vec<&BenchResult>> = 
            std::collections::HashMap::new();
        
        for result in &self.results {
            let component = result.config_name.split('_').next().unwrap_or("Unknown");
            component_results.entry(component.to_string())
                .or_insert_with(Vec::new)
                .push(result);
        }
        
        for (component, results) in component_results {
            println!("\n--- {} ç»„ä»¶æ€§èƒ½æ€»ç»“ ---", component);
            
            let avg_ns_per_event: f64 = results.iter()
                .map(|r| r.nanoseconds_per_event)
                .sum::<f64>() / results.len() as f64;
            
            let max_throughput = results.iter()
                .map(|r| r.events_per_second)
                .fold(0.0, f64::max);
            
            println!("  å¹³å‡å»¶è¿Ÿ: {:.1} ns/äº‹ä»¶", avg_ns_per_event);
            println!("  æœ€å¤§ååé‡: {:.0} äº‹ä»¶/ç§’", max_throughput);
            
            // æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®é…ç½®
            if let Some(best) = results.iter().min_by(|a, b| 
                a.nanoseconds_per_event.partial_cmp(&b.nanoseconds_per_event).unwrap()) {
                println!("  æœ€ä½³é…ç½®: {} ({:.1} ns/äº‹ä»¶)", best.config_name, best.nanoseconds_per_event);
            }
            
            if let Some(worst) = results.iter().max_by(|a, b| 
                a.nanoseconds_per_event.partial_cmp(&b.nanoseconds_per_event).unwrap()) {
                println!("  æœ€å·®é…ç½®: {} ({:.1} ns/äº‹ä»¶)", worst.config_name, worst.nanoseconds_per_event);
            }
        }
        
        println!("\n=== æ€§èƒ½ä¼˜åŒ–å»ºè®® ===");
        self.print_optimization_recommendations();
    }
    
    /// æ‰“å°ä¼˜åŒ–å»ºè®®
    /// Print optimization recommendations
    fn print_optimization_recommendations(&self) {
        println!("1. **æ‰¹é‡å¤§å°ä¼˜åŒ–**:");
        println!("   - æ¨èæ‰¹é‡å¤§å°: 512-2048 ä¸ªäº‹ä»¶");
        println!("   - é¿å…å°æ‰¹é‡ (<32) å¤„ç†ï¼Œä¼šå¢åŠ å•äº‹ä»¶å¼€é”€");
        
        println!("\n2. **å†…å­˜è®¿é—®ä¼˜åŒ–**:");
        println!("   - è€ƒè™‘ä½¿ç”¨ CPUç¼“å­˜å‹å¥½çš„æ•°æ®ç»“æ„");
        println!("   - å‡å°‘åŸå­æ“ä½œé¢‘ç‡ï¼Œä½¿ç”¨æ‰¹é‡åŸå­æ›´æ–°");
        
        println!("\n3. **å¹¶å‘ä¼˜åŒ–**:");
        println!("   - ä½¿ç”¨4-8ä¸ªåˆ†å‘å™¨è·å¾—æœ€ä½³æ€§èƒ½");
        println!("   - é¿å…è¿‡å¤šåˆ†å‘å™¨é€ æˆçš„ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€");
        
        println!("\n4. **é›¶æ‹·è´ä¼˜åŒ–**:");
        println!("   - è€ƒè™‘ä½¿ç”¨æ— é”ç¯å½¢ç¼“å†²åŒºæ›¿ä»£ ArcSwap");
        println!("   - å®ç°æ‰¹é‡å†…å­˜æ˜ å°„ä»¥å‡å°‘ç³»ç»Ÿè°ƒç”¨");
    }
}

#[cfg(test)]
mod bench_tests {
    use super::*;
    
    #[test]
    fn test_lightweight_benchmark() {
        let config = BenchConfig {
            batch_sizes: vec![32, 128],
            dispatcher_counts: vec![2, 4],
            slot_counts: vec![64, 256],
            iterations: 10, // å‡å°‘è¿­ä»£æ¬¡æ•°ä»¥åŠ å¿«æµ‹è¯•
        };
        
        let mut benchmarker = ZeroCopyBenchmarker::new(config);
        benchmarker.run_all_benchmarks();
        
        // éªŒè¯æœ‰ç»“æœäº§ç”Ÿ
        assert!(!benchmarker.results.is_empty());
    }
}