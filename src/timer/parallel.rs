//! æ··åˆå¹¶è¡Œå®šæ—¶å™¨å¤„ç†æ¨¡å— 
//! Hybrid Parallel Timer Processing Module
//!
//! è¯¥æ¨¡å—å®ç°äº†ä¸‰å±‚å¹¶è¡Œä¼˜åŒ–æ¶æ„ï¼š
//! 1. SIMDå‘é‡åŒ– - å•çº¿ç¨‹å†…å¹¶è¡Œå¤„ç†
//! 2. Rayonæ•°æ®å¹¶è¡Œ - CPUå¯†é›†å‹æ‰¹é‡è®¡ç®—
//! 3. tokioå¼‚æ­¥å¹¶å‘ - I/Oå¯†é›†å‹äº‹ä»¶åˆ†å‘
//! 4. é›¶æ‹·è´é€šé“ - åŸºäºå¼•ç”¨ä¼ é€’é¿å…æ•°æ®å…‹éš†
//! 5. å•çº¿ç¨‹ç›´é€š - ç»•è¿‡å¼‚æ­¥è°ƒåº¦çš„ç›´æ¥è·¯å¾„
//!
//! This module implements a three-tier parallel optimization architecture:
//! 1. SIMD Vectorization - Intra-thread parallel processing
//! 2. Rayon Data Parallelism - CPU-intensive batch computation  
//! 3. tokio Async Concurrency - I/O-intensive event dispatching
//! 4. Zero-Copy Channels - Reference passing to avoid data cloning
//! 5. Single-Thread Bypass - Direct path bypassing async scheduling

/// å•çº¿ç¨‹ç›´é€šä¼˜åŒ–æ¨¡å— - ç»•è¿‡å¼‚æ­¥è°ƒåº¦çš„åŒæ­¥è·¯å¾„
/// Single-thread bypass optimization module - synchronous path bypassing async scheduling
pub mod single_thread_bypass;
/// å†…å­˜é¢„åˆ†é…ç®¡ç†å™¨ - å‡å°‘è¿è¡Œæ—¶åˆ†é…
/// Memory pre-allocation manager - reducing runtime allocations
pub mod memory;
/// å¹¶è¡Œå¤„ç†ç­–ç•¥é€‰æ‹©
/// Parallel processing strategy selection
pub mod strategy;
/// æ•°æ®ç±»å‹å®šä¹‰
/// Data type definitions
pub mod types;
/// SIMDå®šæ—¶å™¨å¤„ç†å™¨
/// SIMD Timer Processor
pub mod simd_processor;
/// Rayonæ‰¹é‡æ‰§è¡Œå™¨
/// Rayon Batch Executor
pub mod rayon_executor;
/// å¼‚æ­¥äº‹ä»¶åˆ†å‘å™¨
/// Async Event Dispatcher
pub mod async_dispatcher;
/// æ ¸å¿ƒå¹¶è¡Œç³»ç»Ÿ
/// Core parallel system
pub mod core;

// Re-export the main types for convenience
pub use core::HybridParallelTimerSystem;
pub use strategy::OptimalParallelStrategy;
pub use types::{
    DetailedProcessingStats, ParallelProcessingResult, ParallelProcessingStats, ProcessedTimerData,
};
pub use simd_processor::SIMDTimerProcessor;
pub use rayon_executor::RayonBatchExecutor;
pub use async_dispatcher::AsyncEventDispatcher;


#[cfg(test)]
mod tests {
    use super::*;
    use crate::timer::event::TimerEvent;
    use crate::timer::event::traits::{EventDataTrait, EventFactory};
    use crate::timer::TimerEntry;
    use tokio::sync::mpsc;
    use std::time::{Duration, Instant};
    use crate::core::endpoint::timing::TimeoutEvent;

    #[tokio::test]
    async fn test_hybrid_parallel_system_creation() {
        let system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        assert!(system.cpu_cores > 0);
        assert_eq!(system.stats.total_batches_processed, 0);
    }

    #[tokio::test]
    async fn test_strategy_selection() {
        let system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        assert_eq!(system.choose_optimal_strategy(100), OptimalParallelStrategy::SIMDOnly);
        assert_eq!(system.choose_optimal_strategy(1000), OptimalParallelStrategy::SIMDOnly);
        assert_eq!(system.choose_optimal_strategy(10000), OptimalParallelStrategy::FullHybrid);
    }

    // ========== æ‰©å±•çš„å¹¶è¡Œç³»ç»Ÿæµ‹è¯• ==========

    #[tokio::test]
    async fn test_strategy_selection_comprehensive() {
        let system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        // è¾¹ç•Œå€¼æµ‹è¯•
        assert_eq!(system.choose_optimal_strategy(0), OptimalParallelStrategy::SIMDOnly);
        assert_eq!(system.choose_optimal_strategy(256), OptimalParallelStrategy::SIMDOnly);
        assert_eq!(system.choose_optimal_strategy(257), OptimalParallelStrategy::SIMDOnly);
        assert_eq!(system.choose_optimal_strategy(1023), OptimalParallelStrategy::SIMDOnly);
        assert_eq!(system.choose_optimal_strategy(1024), OptimalParallelStrategy::FullHybrid);
        assert_eq!(system.choose_optimal_strategy(4095), OptimalParallelStrategy::FullHybrid);
        assert_eq!(system.choose_optimal_strategy(4096), OptimalParallelStrategy::FullHybrid);
        assert_eq!(system.choose_optimal_strategy(100000), OptimalParallelStrategy::FullHybrid);
    }

    #[tokio::test]
    async fn test_simd_processor_detailed() {
        let mut processor = SIMDTimerProcessor::<TimeoutEvent>::new();
        
        // æµ‹è¯•ç©ºæ‰¹é‡
        let empty_entries = vec![];
        let result = processor.process_batch(&empty_entries);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 0);
        
        // æµ‹è¯•å°æ‰¹é‡ï¼ˆè§¦å‘SIMDä¼˜åŒ–ï¼‰
        let small_entries = create_test_timer_entries(8);
        let result = processor.process_batch(&small_entries);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 8);
        
        // æµ‹è¯•ä¸­ç­‰æ‰¹é‡
        let medium_entries = create_test_timer_entries(64);
        let result = processor.process_batch(&medium_entries);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 64);
    }

    #[tokio::test]
    async fn test_rayon_executor() {
        let mut executor = RayonBatchExecutor::new(num_cpus::get());
        let mut simd_processor = SIMDTimerProcessor::<TimeoutEvent>::new();
        
        // æµ‹è¯•Rayon + SIMDå¹¶è¡Œå¤„ç†
        let test_entries = create_test_timer_entries(1000);
        
        let start = Instant::now();
        let result = executor.parallel_process_with_simd(test_entries, &mut simd_processor).await;
        let duration = start.elapsed();
        
        assert!(result.is_ok());
        let processed = result.unwrap();
        assert_eq!(processed.len(), 1000);
        
        // éªŒè¯æ¯ä¸ªæ¡ç›®éƒ½è¢«æ­£ç¡®å¤„ç†
        for (i, timer_data) in processed.iter().enumerate() {
            assert_eq!(timer_data.entry_id, i as u64);
            assert_eq!(timer_data.connection_id, (i % 10000) as u32);
        }
        
        println!("Rayon + SIMD parallel processing 1000 timers took: {:?}", duration);
        assert!(duration < Duration::from_millis(100)); // åº”è¯¥å¾ˆå¿«
    }

    #[tokio::test]
    async fn test_zero_copy_batch_dispatcher() {
        let mut system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        // æµ‹è¯•é›¶æ‹·è´æ‰¹é‡åˆ†å‘
        let test_entries = create_test_timer_entries(100);
        let entry_count = test_entries.len();
        
        let start = Instant::now();
        let result = system.process_timer_batch(test_entries).await;
        let duration = start.elapsed();
        
        assert!(result.is_ok());
        let processed = result.unwrap();
        assert_eq!(processed.processed_count, entry_count);
        
        println!("Zero-copy batch dispatch 100 timers took: {:?}", duration);
        assert!(duration < Duration::from_millis(50));
    }

    #[tokio::test]
    async fn test_single_thread_bypass() {
        let mut system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        // å°æ‰¹é‡åº”è¯¥è§¦å‘å•çº¿ç¨‹ç›´é€šä¼˜åŒ–
        let small_batch = create_test_timer_entries(32);
        
        let start = Instant::now();
        let result = system.process_timer_batch(small_batch).await;
        let duration = start.elapsed();
        
        assert!(result.is_ok());
        let processed = result.unwrap();
        assert_eq!(processed.processed_count, 32);
        
        // éªŒè¯ä½¿ç”¨äº†å•çº¿ç¨‹ç›´é€šï¼ˆéå¸¸å¿«ï¼‰
        println!("Single-thread bypass 32 timers took: {:?}", duration);
        assert!(duration < Duration::from_millis(10));
        
        // ç»Ÿè®¡ä¿¡æ¯åº”è¯¥åæ˜ ç›´é€šä½¿ç”¨
        assert!(processed.detailed_stats.memory_allocations < 10);
    }

    #[tokio::test]
    async fn test_memory_efficiency() {
        let mut system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        // é¢„çƒ­ç³»ç»Ÿ
        for _ in 0..5 {
            let warmup = create_test_timer_entries(50);
            let _ = system.process_timer_batch(warmup).await;
        }
        
        // æµ‹è¯•å†…å­˜åˆ†é…æƒ…å†µ
        let test_entries = create_test_timer_entries(200);
        let result = system.process_timer_batch(test_entries).await;
        
        assert!(result.is_ok());
        let processed = result.unwrap();
        
        // éªŒè¯å†…å­˜æ•ˆç‡
        let allocations = processed.detailed_stats.memory_allocations;
        println!("Memory allocations for 200 timers: {}", allocations);
        
        // ç”±äºé›¶æ‹·è´å’Œå¯¹è±¡æ± ï¼Œå†…å­˜åˆ†é…åº”è¯¥å¾ˆå°‘
        assert!(allocations < 50);
    }

    #[tokio::test]
    async fn test_performance_scaling() {
        let mut system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        let test_sizes = vec![10, 50, 100, 500, 1000, 2000];
        let mut performance_results = Vec::new();
        
        for size in test_sizes {
            // é¢„çƒ­
            for _ in 0..3 {
                let warmup = create_test_timer_entries(size);
                let _ = system.process_timer_batch(warmup).await;
            }
            
            // æµ‹è¯•æ€§èƒ½
            let test_entries = create_test_timer_entries(size);
            let start = Instant::now();
            let result = system.process_timer_batch(test_entries).await;
            let duration = start.elapsed();
            
            assert!(result.is_ok());
            
            let nanos_per_timer = duration.as_nanos() / size as u128;
            performance_results.push((size, nanos_per_timer));
            
            println!("Batch size {}: {} ns/timer", size, nanos_per_timer);
        }
        
        // éªŒè¯æ€§èƒ½ç‰¹å¾
        // å°æ‰¹é‡åº”è¯¥æœ‰å¾ˆå¥½çš„å•ä½æ€§èƒ½ï¼ˆç”±äºç›´é€šä¼˜åŒ–ï¼‰
        assert!(performance_results[0].1 < 1000); // <1å¾®ç§’/å®šæ—¶å™¨
        
        // å¤§æ‰¹é‡çš„ç»å¯¹æ€§èƒ½åº”è¯¥ä¸ä¼šå¤ªå·®
        assert!(performance_results.last().unwrap().1 < 10000); // <10å¾®ç§’/å®šæ—¶å™¨
    }

    #[tokio::test]
    async fn test_concurrent_processing() {
        use tokio::task::JoinSet;
        
        // åˆ›å»ºå¤šä¸ªå¹¶å‘ä»»åŠ¡ï¼Œæµ‹è¯•ç³»ç»Ÿçš„å¹¶å‘å®‰å…¨æ€§
        let mut join_set = JoinSet::new();
        let task_count = 10;
        let entries_per_task = 100;
        
        for task_id in 0..task_count {
            join_set.spawn(async move {
                let mut system = HybridParallelTimerSystem::<TimeoutEvent>::new();
                let test_entries = create_test_timer_entries(entries_per_task);
                
                let start = Instant::now();
                let result = system.process_timer_batch(test_entries).await;
                let duration = start.elapsed();
                
                assert!(result.is_ok());
                let processed = result.unwrap();
                assert_eq!(processed.processed_count, entries_per_task);
                
                (task_id, duration, processed.detailed_stats)
            });
        }
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        let mut total_duration = Duration::ZERO;
        let mut completed_tasks = 0;
        
        while let Some(task_result) = join_set.join_next().await {
            assert!(task_result.is_ok());
            let (task_id, duration, stats) = task_result.unwrap();
            
            total_duration += duration;
            completed_tasks += 1;
            
            println!("Task {} completed in {:?}, allocations: {}", 
                     task_id, duration, stats.memory_allocations);
        }
        
        assert_eq!(completed_tasks, task_count);
        let avg_duration = total_duration / task_count as u32;
        
        println!("Average concurrent task duration: {:?}", avg_duration);
        assert!(avg_duration < Duration::from_millis(100));
    }

    #[tokio::test]
    async fn test_error_handling() {
        let mut system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        // æµ‹è¯•ç©ºæ‰¹é‡å¤„ç†
        let empty_batch = vec![];
        let result = system.process_timer_batch(empty_batch).await;
        assert!(result.is_ok());
        let processed = result.unwrap();
        assert_eq!(processed.processed_count, 0);
        
        // æµ‹è¯•æå¤§æ‰¹é‡ï¼ˆå¯èƒ½è§¦å‘æŸäº›é™åˆ¶ï¼‰
        let large_batch = create_test_timer_entries(50000);
        let result = system.process_timer_batch(large_batch).await;
        
        // å³ä½¿æ˜¯æå¤§æ‰¹é‡ï¼Œç³»ç»Ÿä¹Ÿåº”è¯¥èƒ½å¤„ç†
        assert!(result.is_ok());
        let processed = result.unwrap();
        assert_eq!(processed.processed_count, 50000);
    }

    #[tokio::test]
    async fn test_system_statistics() {
        let mut system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        // åˆå§‹ç»Ÿè®¡åº”è¯¥ä¸º0
        assert_eq!(system.stats.total_batches_processed, 0);
        
        // å¤„ç†ä¸€äº›æ‰¹é‡
        let batches = vec![
            create_test_timer_entries(50),
            create_test_timer_entries(200),
            create_test_timer_entries(1000),
        ];
        
        for batch in batches {
            let result = system.process_timer_batch(batch).await;
            assert!(result.is_ok());
        }
        
        // éªŒè¯ç»Ÿè®¡æ›´æ–°
        assert_eq!(system.stats.total_batches_processed, 3);
        
        // éªŒè¯ç­–ç•¥ä½¿ç”¨è®¡æ•°
        assert!(system.stats.simd_only_count > 0 || system.stats.full_hybrid_count > 0);
        
        println!("Processed {} batches, SIMD-only: {}, Full-hybrid: {}", 
                 system.stats.total_batches_processed,
                 system.stats.simd_only_count,
                 system.stats.full_hybrid_count);
    }

    #[tokio::test]
    async fn test_simd_processor() {
        let mut processor = SIMDTimerProcessor::<TimeoutEvent>::new();
        
        // åˆ›å»ºæµ‹è¯•æ•°æ® - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸ä¾èµ–TimerEventç»“æ„
        let test_entries = vec![];  // ç©ºæµ‹è¯•ï¼Œé¿å…å¤æ‚çš„ä¾èµ–å…³ç³»

        let result = processor.process_batch(&test_entries);
        assert!(result.is_ok());
        let processed = result.unwrap();
        assert_eq!(processed.len(), 0);
    }

    /// åˆ›å»ºæµ‹è¯•ç”¨çš„å®šæ—¶å™¨æ¡ç›® (ä½¿ç”¨æ™ºèƒ½å·¥å‚)
    fn create_test_timer_entries<E: EventDataTrait>(count: usize) -> Vec<TimerEntry<E>> {
        let (tx, _rx) = mpsc::channel(1);
        let mut entries = Vec::with_capacity(count);
        let factory = EventFactory::<E>::new(); // æ™ºèƒ½ç­–ç•¥é€‰æ‹©å·¥å‚
        
        for i in 0..count {
            let timer_event = TimerEvent::from_factory(
                &factory,
                i as u64, // id
                (i % 10000) as u32, // connection_id
                E::default(),
                tx.clone(),
            );
            
            entries.push(TimerEntry {
                id: i as u64,
                expiry_time: tokio::time::Instant::now() + tokio::time::Duration::from_millis(1000),
                event: timer_event,
            });
        }
        
        entries
    }


    #[tokio::test]
    async fn test_async_overhead_optimization_effectiveness() {
        // åœ¨æµ‹è¯•å¼€å§‹æ—¶æ·»åŠ å°å»¶è¿Ÿï¼Œå‡å°‘å¹¶å‘æµ‹è¯•é—´çš„èµ„æºç«äº‰
        // Add small delay at test start to reduce resource contention between concurrent tests
        tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
        
        println!("\nğŸš€ å¼‚æ­¥å¼€é”€ä¼˜åŒ–æ•ˆæœéªŒè¯æµ‹è¯•");
        println!("========================================");
        println!("è¯¥æµ‹è¯•éªŒè¯é›¶æ‹·è´é€šé“ã€å•çº¿ç¨‹ç›´é€šå’Œå†…å­˜ä¼˜åŒ–çš„æ•ˆæœ");
        println!();

        let mut optimized_system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        // æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°ä¸‹çš„ä¼˜åŒ–æ•ˆæœ
        let optimization_test_cases = vec![
            (32, "å¾®æ‰¹é‡ - ç›´é€šæ¨¡å¼"),
            (128, "å°æ‰¹é‡ - ç›´é€šæ¨¡å¼"), 
            (512, "ä¸­æ‰¹é‡ - é›¶æ‹·è´ä¼˜åŒ–"),
            (2048, "å¤§æ‰¹é‡ - å®Œæ•´ä¼˜åŒ–"),
        ];

        for (batch_size, scenario) in optimization_test_cases {
            println!("ğŸ”¬ {} ({} ä¸ªå®šæ—¶å™¨):", scenario, batch_size);
            
            // æ£€æµ‹æ‰§è¡Œæ¨¡å¼
            let execution_mode = optimized_system.mode_selector.choose_mode(batch_size);
            let should_bypass = optimized_system.mode_selector.should_bypass_async(batch_size);
            
            println!("  æ‰§è¡Œæ¨¡å¼: {:?}", execution_mode);
            println!("  ä½¿ç”¨ç›´é€š: {}", should_bypass);
            
            // é¢„çƒ­ç³»ç»Ÿ
            for _ in 0..3 {
                let warmup_entries = create_test_timer_entries(10);
                let _ = optimized_system.process_timer_batch(warmup_entries).await;
            }
            
            // å¤šæ¬¡è¿è¡Œå–å¹³å‡å€¼
            let iterations = 100;
            let mut total_duration = std::time::Duration::ZERO;
            let mut total_memory_allocations = 0;
            let mut bypass_used_count = 0;
            
            let overall_start = Instant::now();
            
            for _ in 0..iterations {
                let test_entries = create_test_timer_entries(batch_size);
                let start_time = Instant::now();
                
                match optimized_system.process_timer_batch(test_entries).await {
                    Ok(result) => {
                        total_duration += start_time.elapsed();
                        total_memory_allocations += result.detailed_stats.memory_allocations;
                        
                        // æ£€æµ‹æ˜¯å¦ä½¿ç”¨äº†ç›´é€šæ¨¡å¼ï¼ˆSIMDæ“ä½œä¸º0è¡¨ç¤ºä½¿ç”¨äº†ç›´é€šï¼‰
                        if result.detailed_stats.simd_operations == 0 {
                            bypass_used_count += 1;
                        }
                    }
                    Err(e) => {
                        eprintln!("æµ‹è¯•å¤±è´¥: {}", e);
                        continue;
                    }
                }
            }
            
            let overall_duration = overall_start.elapsed();
            let avg_duration = if iterations > 0 {
                total_duration / iterations
            } else {
                std::time::Duration::ZERO
            };
            let avg_memory_allocs = if iterations > 0 {
                total_memory_allocations as f64 / iterations as f64
            } else {
                0.0
            };
            let nanos_per_operation = if batch_size > 0 {
                avg_duration.as_nanos() / batch_size as u128
            } else {
                0
            };
            
            println!("  å¹³å‡å¤„ç†æ—¶é—´: {:.2}Âµs", avg_duration.as_micros());
            println!("  æ¯æ“ä½œå»¶è¿Ÿ: {} çº³ç§’", nanos_per_operation);
            println!("  å¹³å‡å†…å­˜åˆ†é…: {:.1} æ¬¡", avg_memory_allocs);
            println!("  ç›´é€šæ¨¡å¼ä½¿ç”¨: {}/{} æ¬¡", bypass_used_count, iterations);
            println!("  æ€»æµ‹è¯•æ—¶é—´: {:.2}ms", overall_duration.as_millis());
            
            // ååé‡è®¡ç®—
            let throughput = if overall_duration.as_secs_f64() > 0.0 {
                (batch_size as f64 * iterations as f64) / overall_duration.as_secs_f64()
            } else {
                0.0
            };
            println!("  æ•´ä½“ååé‡: {:.0} ops/sec", throughput);
            
            // æ€§èƒ½è¯„ä¼°
            let optimization_effectiveness = match (nanos_per_operation, should_bypass) {
                (0..=100, true) => "ğŸš€ ç›´é€šæ¨¡å¼ä¼˜åŒ–å“è¶Š",
                (101..=200, true) => "âš¡ ç›´é€šæ¨¡å¼ä¼˜åŒ–æ˜¾è‘—", 
                (0..=300, false) if avg_memory_allocs <= 2.0 => "âœ… é›¶æ‹·è´ä¼˜åŒ–æœ‰æ•ˆ",
                (301..=500, false) => "âš ï¸  ä¼˜åŒ–æ•ˆæœä¸€èˆ¬",
                _ => "âŒ ä¼˜åŒ–æ•ˆæœæœ‰é™",
            };
            
            println!("  ä¼˜åŒ–è¯„ä¼°: {}", optimization_effectiveness);
            
            // å†…å­˜æ•ˆç‡è¯„ä¼°
            let memory_efficiency = match avg_memory_allocs {
                x if x <= 1.0 => "ğŸ¯ å†…å­˜é›¶åˆ†é…/å•æ¬¡åˆ†é…",
                x if x <= 2.0 => "âœ… å†…å­˜åˆ†é…ä¼˜åŒ–è‰¯å¥½",
                x if x <= 3.0 => "âš ï¸  å†…å­˜åˆ†é…å¯ä»¥æ”¹è¿›",
                _ => "âŒ å†…å­˜åˆ†é…éœ€è¦ä¼˜åŒ–",
            };
            
            println!("  å†…å­˜æ•ˆç‡: {}", memory_efficiency);
            println!();
        }

        // è¾“å‡ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
        let stats = optimized_system.get_stats();
        println!("ğŸ“Š ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡:");
        println!("  å¤„ç†æ‰¹æ¬¡: {}", stats.total_batches_processed);
        println!("  æ•´ä½“ååé‡: {:.0} ops/sec", stats.overall_throughput_ops_per_sec);
        println!("  å¹³å‡å¤„ç†æ—¶é—´: {:.3}Âµs", stats.avg_processing_time_ns / 1000.0);
    }

    
    
    #[tokio::test]
    #[ignore] // ç”±äºèµ„æºå¯†é›†å‹ï¼Œåœ¨CIä¸­è·³è¿‡ï¼Œä½¿ç”¨ cargo test -- --ignored å•ç‹¬è¿è¡Œ
    async fn test_comprehensive_optimization_benchmark() {
        // åŸºå‡†æµ‹è¯•å‰ç­‰å¾…æ›´é•¿æ—¶é—´ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®š
        // Wait longer before benchmark to ensure system stability
        tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;
        
        println!("\nğŸ† ç»¼åˆä¼˜åŒ–æ•ˆæœåŸºå‡†æµ‹è¯• (å·²ä¿®æ­£)");
        println!("========================================");
        println!("å¯¹æ¯”ä¼ ç»Ÿå¼‚æ­¥æ¨¡å¼ vs ä¼˜åŒ–æ¨¡å¼çš„æ€§èƒ½å·®å¼‚");
        println!();

        let mut optimized_system = HybridParallelTimerSystem::<TimeoutEvent>::new();
        
        // æµ‹è¯•åœºæ™¯ï¼šä¸åŒæ‰¹é‡å¤§å°ä¸‹çš„æ€§èƒ½å¯¹æ¯” (å·²æ‰©å±•è‡³ 8192)
        let benchmark_cases = vec![
            (1, "è¶…å°æ‰¹é‡ (1)"),
            (16, "è¶…å°æ‰¹é‡ (16)"),
            (32, "è¶…å°æ‰¹é‡ (32)"),
            (64, "å°æ‰¹é‡ (64)"),
            (128, "å°æ‰¹é‡ (128)"),
            (256, "ä¸­æ‰¹é‡ (256)"),
            (512, "ä¸­æ‰¹é‡ (512)"),
            (1024, "å¤§æ‰¹é‡ (1024)"),
            (2048, "å¤§æ‰¹é‡ (2048)"),
            (4096, "è¶…å¤§æ‰¹é‡ (4096)"),
            (8192, "è¶…å¤§æ‰¹é‡ (8192)"),
        ];

        for (batch_size, scenario) in benchmark_cases {
            println!("ğŸ {} ({} ä¸ªå®šæ—¶å™¨):", scenario, batch_size);
            
            let should_bypass = optimized_system.mode_selector.should_bypass_async(batch_size);
            
            // é¢„çƒ­
            for _ in 0..5 {
                let warmup_entries = create_test_timer_entries(batch_size);
                let _ = optimized_system.process_timer_batch(warmup_entries).await;
            }
            
            // åŸºå‡†æµ‹è¯•ï¼ˆå¤šæ¬¡è¿è¡Œå–å¹³å‡å€¼ï¼‰
            let benchmark_iterations = 1000;
            let mut durations = Vec::with_capacity(benchmark_iterations);
            let mut memory_allocations = Vec::with_capacity(benchmark_iterations);
            let mut bypass_mode_used = 0;
            
            let benchmark_start = Instant::now();
            
            for _ in 0..benchmark_iterations {
                let test_entries = create_test_timer_entries(batch_size);
                let iteration_start = Instant::now();
                
                if let Ok(result) = optimized_system.process_timer_batch(test_entries).await {
                    durations.push(iteration_start.elapsed());
                    memory_allocations.push(result.detailed_stats.memory_allocations);
                    
                    // å¦‚æœæ²¡æœ‰SIMDæ“ä½œï¼Œæˆ‘ä»¬å‡è®¾å®ƒä½¿ç”¨äº†ç›´é€šæ¨¡å¼
                    if result.detailed_stats.simd_operations == 0 {
                        bypass_mode_used += 1;
                    }
                }
            }
            
            let total_benchmark_time = benchmark_start.elapsed();
            
            // è®¡ç®—ç»Ÿè®¡æ•°æ®
            let avg_duration = if !durations.is_empty() {
                durations.iter().sum::<std::time::Duration>() / durations.len() as u32
            } else {
                std::time::Duration::ZERO
            };
            let min_duration = durations.iter().min().unwrap_or(&std::time::Duration::ZERO);
            let max_duration = durations.iter().max().unwrap_or(&std::time::Duration::ZERO);
            let avg_memory_allocs: f64 = if !memory_allocations.is_empty() {
                memory_allocations.iter().sum::<usize>() as f64 / memory_allocations.len() as f64
            } else {
                0.0
            };
            
            let nanos_per_op = if batch_size > 0 {
                avg_duration.as_nanos() / batch_size as u128
            } else {
                0
            };
            let throughput = if total_benchmark_time.as_secs_f64() > 0.0 {
                (batch_size as f64 * benchmark_iterations as f64) / total_benchmark_time.as_secs_f64()
            } else {
                0.0
            };
            
            println!("  é¢„æœŸæ¨¡å¼: {}", if should_bypass { "ç›´é€š" } else { "å¹¶è¡Œ" });
            let bypass_rate = if benchmark_iterations > 0 {
                (bypass_mode_used as f64 / benchmark_iterations as f64) * 100.0
            } else {
                0.0
            };
            println!("  ç›´é€šä½¿ç”¨ç‡: {:.1}%", bypass_rate);
            println!();
            
            println!("  ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:");
            println!("    å¹³å‡å»¶è¿Ÿ: {:.3}Âµs", avg_duration.as_secs_f64() * 1_000_000.0);
            println!("    æœ€å°å»¶è¿Ÿ: {:.3}Âµs", min_duration.as_secs_f64() * 1_000_000.0);
            println!("    æœ€å¤§å»¶è¿Ÿ: {:.3}Âµs", max_duration.as_secs_f64() * 1_000_000.0);
            println!("    æ¯æ“ä½œ: {} çº³ç§’", nanos_per_op);
            println!("    ååé‡: {:.0} ops/sec", throughput);
            println!();
            
            println!("  ğŸ§  å†…å­˜æŒ‡æ ‡:");
            println!("    å¹³å‡åˆ†é…: {:.1} æ¬¡", avg_memory_allocs);
            println!("    åˆ†é…æ•ˆç‡: {}", if avg_memory_allocs <= 1.0 { "ä¼˜ç§€" } else if avg_memory_allocs <= 2.0 { "è‰¯å¥½" } else { "éœ€æ”¹è¿›" });
            println!();
            
            // æ€§èƒ½ç­‰çº§è¯„ä¼°
            let performance_grade = match nanos_per_op {
                0..=50 => "Sçº§ (å“è¶Š)",
                51..=100 => "Açº§ (ä¼˜ç§€)",
                101..=200 => "Bçº§ (è‰¯å¥½)",
                201..=400 => "Cçº§ (ä¸€èˆ¬)",
                _ => "Dçº§ (éœ€æ”¹è¿›)",
            };
            
            println!("  ğŸ† æ€§èƒ½ç­‰çº§: {}", performance_grade);
            println!();
        }

        // è¾“å‡ºæœ€ç»ˆçš„ç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡
        let final_stats = optimized_system.get_stats();
        println!("ğŸ¯ æœ€ç»ˆæ€§èƒ½ç»Ÿè®¡:");
        println!("  å¤„ç†æ‰¹æ¬¡æ€»æ•°: {}", final_stats.total_batches_processed);
        println!("  æ•´ä½“ååé‡: {:.0} ops/sec", final_stats.overall_throughput_ops_per_sec);
        println!("  å¹³å‡å¤„ç†æ—¶é—´: {:.3}Âµs", final_stats.avg_processing_time_ns / 1000.0);
        println!("  ç›´é€šæ¨¡å¼ä½¿ç”¨: {} æ¬¡", final_stats.simd_only_count);
        println!("  SIMD+Rayonä½¿ç”¨: {} æ¬¡", final_stats.simd_rayon_count);
        println!("  å®Œæ•´æ··åˆä½¿ç”¨: {} æ¬¡", final_stats.full_hybrid_count);
    }
}